import torch
import math
from torch import nn
from torchvision.models.video.mvit import PositionalEncoding

from model.nullion import ModelConfig, Attention, precompute_freqs_cis

def test_attention():
    """æµ‹è¯•æ³¨æ„åŠ›æœºåˆ¶"""
    config = ModelConfig()
    attention = Attention(config)
    batch_size = 2
    seq_len = 512
    x = torch.randn(batch_size, seq_len, config.hidden_size)

    head_dim = config.hidden_size // config.num_attention_heads
    freqs_cos, freqs_sin = precompute_freqs_cis(
        dim=head_dim,
        end=config.max_position_embeddings
    )

    # ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„åˆ‡ç‰‡ï¼Œè·å–å‰seq_lenä¸ªä½ç½®çš„ç¼–ç 
    position_embeddings = (
        freqs_cos[:seq_len],  # å½¢çŠ¶: [seq_len, head_dim]
        freqs_sin[:seq_len]   # å½¢çŠ¶: [seq_len, head_dim]
    )

    print(f"æŸ¥è¯¢/é”®å½¢çŠ¶: {x.shape}")
    print(f"ä½ç½®ç¼–ç coså½¢çŠ¶: {position_embeddings[0].shape}")
    print(f"ä½ç½®ç¼–ç sinå½¢çŠ¶: {position_embeddings[1].shape}")

    output = attention(x, position_embeddings)

    print(f"è¾“å‡ºå½¢çŠ¶: {output.shape}")
    assert output.shape == x.shape, f"è¾“å…¥è¾“å‡ºç»´åº¦ä¸ä¸€è‡´! è¾“å…¥: {x.shape}, è¾“å‡º: {output.shape}"
    print("æµ‹è¯•æˆåŠŸ: è¾“å…¥è¾“å‡ºç»´åº¦ä¸€è‡´")

def test_shorter_sequence():
    """æµ‹è¯•è¾ƒçŸ­åºåˆ—"""
    config = ModelConfig()
    attention = Attention(config)
    batch_size = 2
    seq_len = 64
    x = torch.randn(batch_size, seq_len, config.hidden_size)

    head_dim = config.hidden_size // config.num_attention_heads
    freqs_cos, freqs_sin = precompute_freqs_cis(
        dim=head_dim,
        end=config.max_position_embeddings
    )

    position_embeddings = (
        freqs_cos[:seq_len],
        freqs_sin[:seq_len]
    )

    output = attention(x, position_embeddings)
    assert output.shape == x.shape, f"è¾“å…¥è¾“å‡ºç»´åº¦ä¸ä¸€è‡´! è¾“å…¥: {x.shape}, è¾“å‡º: {output.shape}"
    print("çŸ­åºåˆ—æµ‹è¯•æˆåŠŸ")

def test_different_config():
    """æµ‹è¯•ä¸åŒé…ç½®"""
    config = ModelConfig(hidden_size=256, num_attention_heads=4)
    attention = Attention(config)
    batch_size = 2
    seq_len = 32
    x = torch.randn(batch_size, seq_len, config.hidden_size)

    head_dim = config.hidden_size // config.num_attention_heads
    freqs_cos, freqs_sin = precompute_freqs_cis(
        dim=head_dim,
        end=config.max_position_embeddings
    )

    position_embeddings = (
        freqs_cos[:seq_len],
        freqs_sin[:seq_len]
    )

    output = attention(x, position_embeddings)
    assert output.shape == x.shape, f"è¾“å…¥è¾“å‡ºç»´åº¦ä¸ä¸€è‡´! è¾“å…¥: {x.shape}, è¾“å‡º: {output.shape}"
    print("ä¸åŒé…ç½®æµ‹è¯•æˆåŠŸ")

if __name__ == "__main__":
    print("å¼€å§‹æµ‹è¯•æ³¨æ„åŠ›æœºåˆ¶...\n")

    test_attention()
    test_shorter_sequence()
    test_different_config()

    print("\nğŸ‰ æ‰€æœ‰æ³¨æ„åŠ›æµ‹è¯•é€šè¿‡!")
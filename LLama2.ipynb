{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-15T07:39:57.132369Z",
     "start_time": "2025-09-15T07:39:54.995039Z"
    }
   },
   "source": [
    "from transformers import PretrainedConfig\n",
    "\n",
    "class ModelConfig(PretrainedConfig):\n",
    "    model_type = \"Tiny-K\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            dim: int = 768, # 模型维度\n",
    "            n_layers: int = 12, # Transformer的层数\n",
    "            n_heads: int = 16, # 注意力机制的头数\n",
    "            n_kv_heads: int = 8, # 键值头的数量\n",
    "            vocab_size: int = 6144, # 词汇表大小\n",
    "            hidden_dim: int = None, # 隐藏层维度\n",
    "            multiple_of: int = 64,\n",
    "            norm_eps: float = 1e-5, # 归一化层的eps\n",
    "            max_seq_len: int = 512, # 最大序列长度\n",
    "            dropout: float = 0.0, # dropout概率\n",
    "            flash_attn: bool = True, # 是否使用Flash Attention\n",
    "            **kwargs,\n",
    "    ):\n",
    "        self.dim = dim\n",
    "        self.n_layers = n_layers\n",
    "        self.n_heads = n_heads\n",
    "        self.n_kv_heads = n_kv_heads\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.multiple_of = multiple_of\n",
    "        self.norm_eps = norm_eps\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.dropout = dropout\n",
    "        self.flash_attn = flash_attn\n",
    "        super().__init__(**kwargs)\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T07:39:57.502814Z",
     "start_time": "2025-09-15T07:39:57.499881Z"
    }
   },
   "cell_type": "code",
   "source": "import torch.nn as nn",
   "id": "6baaa3ad23b85162",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T07:39:57.518307Z",
     "start_time": "2025-09-15T07:39:57.514155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, dim: int, eps: float):\n",
    "        super().__init__()\n",
    "        # eps是为了防止除以0的情况\n",
    "        self.eps = eps\n",
    "        # weight是一个可学习的参数，全部初始化为1\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x):\n",
    "        # 计算RMSNorm的核心部分\n",
    "        # x.pow(2).mean(-1, keepdim=True)计算了输入x的平方的均值\n",
    "        # torch.rsqrt是平方根的倒数，这样就得到了RMSNorm的分母部分，再加上eps防止分母为0\n",
    "        # 最后乘以x，得到RMSNorm的结果\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # forward函数是模型的前向传播\n",
    "        # 首先将输入x转为float类型，然后进行RMSNorm，最后再转回原来的数据类型\n",
    "        # 最后乘以weight，这是RMSNorm的一个可学习的缩放因子\n",
    "        output = self._norm(x.float()).type_as(x)\n",
    "        return output * self.weight\n"
   ],
   "id": "aa2c354ab76730ea",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T07:39:57.533547Z",
     "start_time": "2025-09-15T07:39:57.525440Z"
    }
   },
   "cell_type": "code",
   "source": "import torch",
   "id": "8731dbf6c30c7782",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T07:39:57.545221Z",
     "start_time": "2025-09-15T07:39:57.540181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def repeat_kv(x: torch.Tensor, n_rep: int) -> torch.Tensor:\n",
    "    # 获取输入张量的形状：批量大小、序列长度、键/值对头的数量、每个头的维度大小\n",
    "    bs, slen, n_kv_heads, head_dim = x.shape\n",
    "\n",
    "    # 如果重复次数为1，则不需要重复，直接返回原始张量\n",
    "    if n_rep == 1:\n",
    "        return x\n",
    "\n",
    "    # 对张量进行扩展和重塑操作以重复键值对\n",
    "    return (\n",
    "        x[:, :, :, None, :]  # 在第四个维度（头的维度前）添加一个新的维度\n",
    "        .expand(bs, slen, n_kv_heads, n_rep, head_dim)  # 将新添加的维度扩展到n_rep大小，实现重复的效果\n",
    "        .reshape(bs, slen, n_kv_heads * n_rep, head_dim)  # 重新塑形，合并键/值对头的数量和重复次数的维度\n",
    "    )\n"
   ],
   "id": "617358a306f9b9ee",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T07:39:57.557192Z",
     "start_time": "2025-09-15T07:39:57.552889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 注意：此处的dim应为 dim//n_head，因为我们是对每个head进行旋转嵌入\n",
    "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
    "    # torch.arange(0, dim, 2)[: (dim // 2)].float()生成了一个从0开始，步长为2的序列，长度为dim的一半\n",
    "    # 然后每个元素除以dim，再取theta的倒数，得到频率\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "    # 生成一个从0到end的序列，长度为end\n",
    "    t = torch.arange(end, device=freqs.device)\n",
    "    # 计算外积，得到一个二维矩阵，每一行是t的元素乘以freqs的元素\n",
    "    freqs = torch.outer(t, freqs).float()\n",
    "    # 计算频率的余弦值，得到实部\n",
    "    freqs_cos = torch.cos(freqs)\n",
    "    # 计算频率的正弦值，得到虚部\n",
    "    freqs_sin = torch.sin(freqs)\n",
    "    return freqs_cos, freqs_sin\n"
   ],
   "id": "219195d4f8b975fa",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T07:39:57.573761Z",
     "start_time": "2025-09-15T07:39:57.564251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n",
    "    # 获取x的维度数\n",
    "    ndim = x.ndim\n",
    "\n",
    "    # 断言，确保1在x的维度范围内\n",
    "    assert 0 <= 1 < ndim\n",
    "\n",
    "    # 断言，确保freqs_cis的形状与x的第二维和最后一维相同\n",
    "    assert freqs_cis.shape == (x.shape[1], x.shape[-1])\n",
    "\n",
    "    # 构造一个新的形状，除了第二维和最后一维，其他维度都为1，这样做是为了能够将freqs_cis与x进行广播操作\n",
    "    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n",
    "\n",
    "    # 将freqs_cis调整为新的形状，并返回\n",
    "    return freqs_cis.view(shape)\n"
   ],
   "id": "6fc4ad13019e82b6",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T07:39:57.585013Z",
     "start_time": "2025-09-15T07:39:57.579932Z"
    }
   },
   "cell_type": "code",
   "source": "from typing import Tuple",
   "id": "64ccb9744312fb00",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T07:39:57.601171Z",
     "start_time": "2025-09-15T07:39:57.594132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def apply_rotary_emb(\n",
    "    xq: torch.Tensor,\n",
    "    xk: torch.Tensor,\n",
    "    freqs_cos: torch.Tensor,\n",
    "    freqs_sin: torch.Tensor\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "\n",
    "    # 将查询和键张量转换为浮点数，并重塑形状以分离实部和虚部\n",
    "    xq_r, xq_i = xq.float().reshape(xq.shape[:-1] + (-1, 2)).unbind(-1)\n",
    "    xk_r, xk_i = xk.float().reshape(xk.shape[:-1] + (-1, 2)).unbind(-1)\n",
    "    print(xq_r.shape, xk_i.shape)\n",
    "\n",
    "    # 重新塑形频率张量以进行广播\n",
    "    freqs_cos = reshape_for_broadcast(freqs_cos, xq_r)\n",
    "    freqs_sin = reshape_for_broadcast(freqs_sin, xq_r)\n",
    "\n",
    "    # 应用旋转，分别计算旋转后的实部和虚部\n",
    "    xq_out_r = xq_r * freqs_cos - xq_i * freqs_sin\n",
    "    xq_out_i = xq_r * freqs_sin + xq_i * freqs_cos\n",
    "    xk_out_r = xk_r * freqs_cos - xk_i * freqs_sin\n",
    "    xk_out_i = xk_r * freqs_sin + xk_i * freqs_cos\n",
    "\n",
    "    # 将最后两个维度合并，并还原为原始张量的形状\n",
    "    xq_out = torch.stack([xq_out_r, xq_out_i], dim=-1).flatten(3)\n",
    "    xk_out = torch.stack([xk_out_r, xk_out_i], dim=-1).flatten(3)\n",
    "\n",
    "    return xq_out.type_as(xq), xk_out.type_as(xk)\n"
   ],
   "id": "c51eb6e37f568d9c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T07:39:57.644119Z",
     "start_time": "2025-09-15T07:39:57.609285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "xq = torch.randn(1, 50, 6, 48) # bs, seq_len, dim//n_head, n_head_dim\n",
    "xk = torch.randn(1, 50, 6, 48) # bs, seq_len, dim//n_head, n_head_dim\n",
    "\n",
    "# 使用 precompute_freqs_cis 函数获取 sin和cos\n",
    "cos, sin = precompute_freqs_cis(288//6, 50)\n",
    "print(cos.shape, sin.shape)\n",
    "xq_out, xk_out = apply_rotary_emb(xq, xk, cos, sin)\n",
    "\n",
    "xq_out.shape, xk_out.shape\n"
   ],
   "id": "c3e69aaf79b265ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 24]) torch.Size([50, 24])\n",
      "torch.Size([1, 50, 6, 24]) torch.Size([1, 50, 6, 24])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 50, 6, 48]), torch.Size([1, 50, 6, 48]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T07:39:57.675543Z",
     "start_time": "2025-09-15T07:39:57.659966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, args: ModelConfig):\n",
    "        super().__init__()\n",
    "        # 根据是否指定n_kv_heads，确定用于键（key）和值（value）的头的数量。\n",
    "        self.n_kv_heads = args.n_heads if args.n_kv_heads is None else args.n_kv_heads\n",
    "        # 确保总头数可以被键值头数整除。\n",
    "        assert args.n_heads % self.n_kv_heads == 0\n",
    "\n",
    "        # 模型并行处理大小，默认为1。\n",
    "        model_parallel_size = 1\n",
    "        # 本地计算头数，等于总头数除以模型并行处理大小。\n",
    "        self.n_local_heads = args.n_heads // model_parallel_size\n",
    "        # 本地键值头数，等于键值头数除以模型并行处理大小。\n",
    "        self.n_local_kv_heads = self.n_kv_heads // model_parallel_size\n",
    "        # 重复次数，用于扩展键和值的尺寸。\n",
    "        self.n_rep = self.n_local_heads // self.n_local_kv_heads\n",
    "        # 每个头的维度，等于模型维度除以头的总数。\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "\n",
    "        # 定义权重矩阵。\n",
    "        self.wq = nn.Linear(args.dim, args.n_heads * self.head_dim, bias=False)\n",
    "        self.wk = nn.Linear(args.dim, self.n_kv_heads * self.head_dim, bias=False)\n",
    "        self.wv = nn.Linear(args.dim, self.n_kv_heads * self.head_dim, bias=False)\n",
    "        # 输出权重矩阵。\n",
    "        self.wo = nn.Linear(args.n_heads * self.head_dim, args.dim, bias=False)\n",
    "\n",
    "        # 定义dropout。\n",
    "        self.attn_dropout = nn.Dropout(args.dropout)\n",
    "        self.resid_dropout = nn.Dropout(args.dropout)\n",
    "        # 保存dropout概率。\n",
    "        self.dropout = args.dropout\n",
    "\n",
    "        # 检查是否使用Flash Attention（需要PyTorch >= 2.0）。\n",
    "        self.flash = hasattr(torch.nn.functional, 'scaled_dot_product_attention')\n",
    "        if not self.flash:\n",
    "            # 若不支持Flash Attention，则使用手动实现的注意力机制，并设置mask。\n",
    "            print(\"WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\")\n",
    "            # 创建一个上三角矩阵，用于遮蔽未来信息。\n",
    "            mask = torch.full((1, 1, args.max_seq_len, args.max_seq_len), float(\"-inf\"))\n",
    "            mask = torch.triu(mask, diagonal=1)\n",
    "            # 注册为模型的缓冲区\n",
    "            self.register_buffer(\"mask\", mask)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, freqs_cos: torch.Tensor, freqs_sin: torch.Tensor):\n",
    "        # 获取批次大小和序列长度，[batch_size, seq_len, dim]\n",
    "        bsz, seqlen, _ = x.shape\n",
    "\n",
    "        # 计算查询（Q）、键（K）、值（V）。\n",
    "        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\n",
    "        # 调整形状以适应头的维度。\n",
    "        xq = xq.view(bsz, seqlen, self.n_local_heads, self.head_dim)\n",
    "        xk = xk.view(bsz, seqlen, self.n_local_kv_heads, self.head_dim)\n",
    "        xv = xv.view(bsz, seqlen, self.n_local_kv_heads, self.head_dim)\n",
    "\n",
    "        # 应用旋转位置嵌入（RoPE）。\n",
    "        xq, xk = apply_rotary_emb(xq, xk, freqs_cos, freqs_sin)\n",
    "\n",
    "        # 对键和值进行扩展以适应重复次数。\n",
    "        xk = repeat_kv(xk, self.n_rep)\n",
    "        xv = repeat_kv(xv, self.n_rep)\n",
    "\n",
    "        # 将头作为批次维度处理。\n",
    "        xq = xq.transpose(1, 2)\n",
    "        xk = xk.transpose(1, 2)\n",
    "        xv = xv.transpose(1, 2)\n",
    "\n",
    "        # 根据是否支持Flash Attention，选择实现方式。\n",
    "        if self.flash:\n",
    "            # 使用Flash Attention。\n",
    "            output = torch.nn.functional.scaled_dot_product_attention(xq, xk, xv, attn_mask=None, dropout_p=self.dropout if self.training else 0.0, is_causal=True)\n",
    "        else:\n",
    "            # 使用手动实现的注意力机制。\n",
    "            scores = torch.matmul(xq, xk.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
    "            assert hasattr(self, 'mask')\n",
    "            scores = scores + self.mask[:, :, :seqlen, :seqlen]\n",
    "            scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n",
    "            scores = self.attn_dropout(scores)\n",
    "            output = torch.matmul(scores, xv)\n",
    "\n",
    "        # 恢复时间维度并合并头。\n",
    "        output = output.transpose(1, 2).contiguous().view(bsz, seqlen, -1)\n",
    "\n",
    "        # 最终投影回残差流。\n",
    "        output = self.wo(output)\n",
    "        output = self.resid_dropout(output)\n",
    "        return output\n"
   ],
   "id": "3e21a6ef7e28a7b4",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T07:39:57.730626Z",
     "start_time": "2025-09-15T07:39:57.684527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建Attention实例\n",
    "\n",
    "args = ModelConfig()\n",
    "\n",
    "attention_model = Attention(args)\n",
    "\n",
    "# 模拟输入数据\n",
    "batch_size = 1\n",
    "seq_len = 50  # 假设实际使用的序列长度为50\n",
    "dim = args.dim\n",
    "x = torch.rand(batch_size, seq_len, dim)  # 随机生成输入张量\n",
    "print(x.shape)\n",
    "# freqs_cos = torch.rand(seq_len, dim // 2)  # 模拟cos频率，用于RoPE\n",
    "# freqs_sin = torch.rand(seq_len, dim // 2)  # 模拟sin频率，用于RoPE\n",
    "\n",
    "freqs_cos, freqs_sin = precompute_freqs_cis(dim//args.n_heads, seq_len)\n",
    "\n",
    "# 运行Attention模型\n",
    "output = attention_model(x, freqs_cos, freqs_sin)\n",
    "\n",
    "# attention出来之后的形状 依然是[batch_size, seq_len, dim]\n",
    "print(\"Output shape:\", output.shape)\n"
   ],
   "id": "c7545305c1188e5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50, 768])\n",
      "torch.Size([1, 50, 16, 24]) torch.Size([1, 50, 8, 24])\n",
      "Output shape: torch.Size([1, 50, 768])\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T07:39:57.759891Z",
     "start_time": "2025-09-15T07:39:57.754755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, dim: int, hidden_dim: int, multiple_of: int, dropout: float):\n",
    "        super().__init__()\n",
    "        # 如果没有指定隐藏层的维度，我们将其设置为输入维度的4倍\n",
    "        # 然后将其减少到2/3，最后确保它是multiple_of的倍数\n",
    "        if hidden_dim is None:\n",
    "            hidden_dim = 4 * dim\n",
    "            hidden_dim = int(2 * hidden_dim / 3)\n",
    "            hidden_dim = multiple_of * ((hidden_dim + multiple_of - 1) // multiple_of)\n",
    "        # 定义第一层线性变换，从输入维度到隐藏维度\n",
    "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        # 定义第二层线性变换，从隐藏维度到输入维度\n",
    "        self.w2 = nn.Linear(hidden_dim, dim, bias=False)\n",
    "        # 定义第三层线性变换，从输入维度到隐藏维度\n",
    "        self.w3 = nn.Linear(dim, hidden_dim, bias=False)\n",
    "        # 定义dropout层，用于防止过拟合\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向传播函数\n",
    "        # 首先，输入x通过第一层线性变换和SILU激活函数\n",
    "        # 然后，结果乘以输入x通过第三层线性变换的结果\n",
    "        # 最后，通过第二层线性变换和dropout层\n",
    "        return self.dropout(self.w2(F.silu(self.w1(x)) * self.w3(x)))\n"
   ],
   "id": "fb71bfd70b1e0d24",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T07:39:57.777251Z",
     "start_time": "2025-09-15T07:39:57.766042Z"
    }
   },
   "cell_type": "code",
   "source": "import torch.nn.functional as F",
   "id": "ebe7655a08add687",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T07:39:57.835448Z",
     "start_time": "2025-09-15T07:39:57.785303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建MLP实例\n",
    "mlp = MLP(args.dim, args.hidden_dim, args.multiple_of, args.dropout)\n",
    "# 随机生成数据\n",
    "x = torch.randn(1, 50, args.dim)\n",
    "# 运行MLP模型\n",
    "output = mlp(x)\n",
    "print(output.shape)\n"
   ],
   "id": "f0d10507196a36da",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50, 768])\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T07:39:57.846136Z",
     "start_time": "2025-09-15T07:39:57.841912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, layer_id: int, args: ModelConfig):\n",
    "        super().__init__()\n",
    "        # 定义多头注意力的头数\n",
    "        self.n_heads = args.n_heads\n",
    "        # 定义输入维度\n",
    "        self.dim = args.dim\n",
    "        # 定义每个头的维度，等于输入维度除以头数\n",
    "        self.head_dim = args.dim // args.n_heads\n",
    "        # 定义LLaMA2Attention对象，用于进行多头注意力计算\n",
    "        self.attention = Attention(args)\n",
    "        # 定义LLaMAMLP对象，用于进行前馈神经网络计算\n",
    "        self.feed_forward = MLP(\n",
    "            dim=args.dim,\n",
    "            hidden_dim=args.hidden_dim,\n",
    "            multiple_of=args.multiple_of,\n",
    "            dropout=args.dropout,\n",
    "        )\n",
    "        # 定义层的ID\n",
    "        self.layer_id = layer_id\n",
    "        # 定义注意力计算的归一化层\n",
    "        self.attention_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "        # 定义前馈神经网络计算的归一化层\n",
    "        self.ffn_norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "\n",
    "    def forward(self, x, freqs_cos, freqs_sin):\n",
    "        # 前向传播函数\n",
    "        # 首先，输入x经过注意力归一化层，然后进行注意力计算，结果与输入x相加得到h\n",
    "        # 然后，h经过前馈神经网络归一化层，然后进行前馈神经网络计算，结果与h相加得到输出\n",
    "        h = x + self.attention.forward(self.attention_norm(x), freqs_cos, freqs_sin)\n",
    "        out = h + self.feed_forward.forward(self.ffn_norm(h))\n",
    "        return out\n"
   ],
   "id": "8663df0e691cb756",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T07:39:58.098657Z",
     "start_time": "2025-09-15T07:39:58.022054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建LLaMADecoderLayer实例\n",
    "decoderlayer = DecoderLayer(0, args)\n",
    "\n",
    "# 模拟输入数据\n",
    "dim = args.dim\n",
    "seq_len = 50\n",
    "\n",
    "x = torch.randn(1, seq_len, dim) # [bs, seq_len, dim]\n",
    "\n",
    "freqs_cos, freqs_sin = precompute_freqs_cis(dim//args.n_heads, seq_len)\n",
    "\n",
    "out = decoderlayer(x, freqs_cos, freqs_sin)\n",
    "\n",
    "print(out.shape) # 形状和输入的x一样 [batch_size, seq_len, dim]\n"
   ],
   "id": "9a0b0b90a708b672",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50, 16, 24]) torch.Size([1, 50, 8, 24])\n",
      "torch.Size([1, 50, 768])\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T07:40:00.761858Z",
     "start_time": "2025-09-15T07:39:58.434260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import PreTrainedModel\n",
    "from typing import Optional"
   ],
   "id": "5bdcc3d5f38e71ae",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T07:40:00.877933Z",
     "start_time": "2025-09-15T07:40:00.866936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Transformer(PreTrainedModel):\n",
    "    config_class = ModelConfig  # 配置类\n",
    "    last_loss: Optional[torch.Tensor] # 记录最后一次计算的损失\n",
    "\n",
    "    def __init__(self, args: ModelConfig = None):\n",
    "        super().__init__(args)\n",
    "        # 初始化模型参数\n",
    "        self.args = args\n",
    "        # 词汇表大小\n",
    "        self.vocab_size = args.vocab_size\n",
    "        # 层数\n",
    "        self.n_layers = args.n_layers\n",
    "\n",
    "        # 词嵌入层\n",
    "        self.tok_embeddings = nn.Embedding(args.vocab_size, args.dim)\n",
    "        # Dropout层\n",
    "        self.dropout = nn.Dropout(args.dropout)\n",
    "        # Decoder层\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for layer_id in range(args.n_layers):\n",
    "            self.layers.append(DecoderLayer(layer_id, args))\n",
    "        # 归一化层\n",
    "        self.norm = RMSNorm(args.dim, eps=args.norm_eps)\n",
    "        # 输出层\n",
    "        self.output = nn.Linear(args.dim, args.vocab_size, bias=False)\n",
    "\n",
    "        # 将词嵌入层的权重与输出层的权重共享\n",
    "        self.tok_embeddings.weight = self.output.weight\n",
    "\n",
    "        # 预计算相对位置嵌入的频率\n",
    "        freqs_cos, freqs_sin = precompute_freqs_cis(self.args.dim // self.args.n_heads, self.args.max_seq_len)\n",
    "        self.register_buffer(\"freqs_cos\", freqs_cos, persistent=False)\n",
    "        self.register_buffer(\"freqs_sin\", freqs_sin, persistent=False)\n",
    "\n",
    "        # 初始化所有权重\n",
    "        self.apply(self._init_weights)\n",
    "        # 对残差投影进行特殊的缩放初始化\n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('w3.weight') or pn.endswith('wo.weight'):\n",
    "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * args.n_layers))\n",
    "\n",
    "        # 初始化最后一次前向传播的损失属性\n",
    "        self.last_loss = None\n",
    "        self.OUT = CausalLMOutputWithPast()  # 输出容器\n",
    "        self._no_split_modules = [name for name, _ in self.named_modules()]  # 不分割的模块列表\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        # 初始化权重的函数\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor, targets: Optional[torch.Tensor] = None, **kwargs) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        - tokens: Optional[torch.Tensor], 输入 token 张量。\n",
    "        - targets: Optional[torch.Tensor], 目标 token 张量。\n",
    "        - kv_cache: bool, 是否使用键值缓存。\n",
    "        - kwargs: 其他关键字参数。\n",
    "\n",
    "        - self.OUT: CausalLMOutputWithPast, 包含 logits 和损失。\n",
    "        \"\"\"\n",
    "\n",
    "        if 'input_ids' in kwargs:\n",
    "            tokens = kwargs['input_ids']\n",
    "        if 'attention_mask' in kwargs:\n",
    "            targets = kwargs['attention_mask']\n",
    "\n",
    "        # 前向传播函数\n",
    "        _bsz, seqlen = tokens.shape\n",
    "        # 通过词嵌入层和Dropout层\n",
    "        h = self.tok_embeddings(tokens)\n",
    "        h = self.dropout(h)\n",
    "        # 获取相对位置嵌入的频率\n",
    "        freqs_cos = self.freqs_cos[:seqlen]\n",
    "        freqs_sin = self.freqs_sin[:seqlen]\n",
    "\n",
    "        # 通过Decoder层\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, freqs_cos, freqs_sin)\n",
    "        # 通过归一化层\n",
    "        h = self.norm(h)\n",
    "\n",
    "        if targets is not None:\n",
    "            # 如果给定了目标，计算损失\n",
    "            logits = self.output(h)\n",
    "            self.last_loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=0, reduction='none')\n",
    "        else:\n",
    "            # 推理时的小优化：只对最后一个位置的输出进行前向传播\n",
    "            logits = self.output(h[:, [-1], :])\n",
    "            self.last_loss = None\n",
    "\n",
    "        # 设置输出\n",
    "        self.OUT.__setitem__('logits', logits)\n",
    "        self.OUT.__setitem__('last_loss', self.last_loss)\n",
    "        return self.OUT\n",
    "\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def generate(self, idx, stop_id=None, max_new_tokens=256, temperature=1.0, top_k=None):\n",
    "        \"\"\"\n",
    "        给定输入序列 idx（形状为 (bz,seq_len) 的长整型张量），通过多次生成新 token 来完成序列。\n",
    "        在 model.eval() 模式下运行。效率较低的采样版本，没有使用键k/v cache。\n",
    "        \"\"\"\n",
    "        index = idx.shape[1]\n",
    "        for _ in range(max_new_tokens):\n",
    "            # 如果序列上下文过长，截断它到最大长度\n",
    "            idx_cond = idx if idx.size(1) <= self.args.max_seq_len else idx[:, -self.args.max_seq_len:]\n",
    "\n",
    "            # 前向传播获取序列中最后一个位置的 logits\n",
    "            logits = self(idx_cond).logits\n",
    "            logits = logits[:, -1, :] # 只保留最后一个时间步的输出\n",
    "\n",
    "            if temperature == 0.0:\n",
    "                # 选择最有可能的索引\n",
    "                _, idx_next = torch.topk(logits, k=1, dim=-1)\n",
    "            else:\n",
    "                # 缩放 logits 并应用 softmax\n",
    "                logits = logits / temperature\n",
    "                if top_k is not None:\n",
    "                    v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                    logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "                probs = F.softmax(logits, dim=-1)\n",
    "                idx_next = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "\n",
    "            if idx_next == stop_id:\n",
    "                break\n",
    "\n",
    "            # 将采样的索引添加到序列中并继续\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "        return idx[:, index:] # 只返回生成的token\n"
   ],
   "id": "348575ad109d9eff",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T07:40:00.916817Z",
     "start_time": "2025-09-15T07:40:00.888236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "from transformers.modeling_outputs import CausalLMOutputWithPast\n"
   ],
   "id": "3628bf043ac1462c",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T07:40:02.275252Z",
     "start_time": "2025-09-15T07:40:00.941276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LLaMA2Model.forward 接受两个参数，tokens和targets，其中tokens是输入的张量, 应为int类型\n",
    "x = torch.randint(0, 6144, (1, 50)) # [bs, seq_len]\n",
    "# 实例化LLaMA2Model\n",
    "model = Transformer(args=args)\n",
    "# 计算model的全部参数\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print('Number of parameters:', num_params)\n",
    "\n",
    "out = model(x)\n",
    "print(out.logits.shape) # [batch_size, 1, vocab_size]\n"
   ],
   "id": "46626fbf2d888e23",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 82594560\n",
      "torch.Size([1, 50, 16, 24]) torch.Size([1, 50, 8, 24])\n",
      "torch.Size([1, 50, 16, 24]) torch.Size([1, 50, 8, 24])\n",
      "torch.Size([1, 50, 16, 24]) torch.Size([1, 50, 8, 24])\n",
      "torch.Size([1, 50, 16, 24]) torch.Size([1, 50, 8, 24])\n",
      "torch.Size([1, 50, 16, 24]) torch.Size([1, 50, 8, 24])\n",
      "torch.Size([1, 50, 16, 24]) torch.Size([1, 50, 8, 24])\n",
      "torch.Size([1, 50, 16, 24]) torch.Size([1, 50, 8, 24])\n",
      "torch.Size([1, 50, 16, 24]) torch.Size([1, 50, 8, 24])\n",
      "torch.Size([1, 50, 16, 24]) torch.Size([1, 50, 8, 24])\n",
      "torch.Size([1, 50, 16, 24]) torch.Size([1, 50, 8, 24])\n",
      "torch.Size([1, 50, 16, 24]) torch.Size([1, 50, 8, 24])\n",
      "torch.Size([1, 50, 16, 24]) torch.Size([1, 50, 8, 24])\n",
      "torch.Size([1, 1, 6144])\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T07:40:02.362028Z",
     "start_time": "2025-09-15T07:40:02.356890Z"
    }
   },
   "cell_type": "code",
   "source": "model",
   "id": "75bee5849fc58e02",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (tok_embeddings): Embedding(6144, 768)\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0-11): 12 x DecoderLayer(\n",
       "      (attention): Attention(\n",
       "        (wq): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wk): Linear(in_features=768, out_features=384, bias=False)\n",
       "        (wv): Linear(in_features=768, out_features=384, bias=False)\n",
       "        (wo): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (feed_forward): MLP(\n",
       "        (w1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "        (w2): Linear(in_features=2048, out_features=768, bias=False)\n",
       "        (w3): Linear(in_features=768, out_features=2048, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (attention_norm): RMSNorm()\n",
       "      (ffn_norm): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (norm): RMSNorm()\n",
       "  (output): Linear(in_features=768, out_features=6144, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T06:02:26.212212Z",
     "start_time": "2025-09-15T06:02:26.209978Z"
    }
   },
   "cell_type": "markdown",
   "source": "# Tokenizer训练",
   "id": "eebcfb53a80dd86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T07:40:02.388822Z",
     "start_time": "2025-09-15T07:40:02.385675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm  # 正确导入方式\n",
    "import json"
   ],
   "id": "e2830662711cbd68",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T07:24:16.599175Z",
     "start_time": "2025-09-15T07:17:57.371036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_text(text, chunk_size=512):\n",
    "    \"\"\"将文本按指定长度切分成块\"\"\"\n",
    "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "input_file = '/home/chenyinlin/Data/seq-monkey/mobvoi_seq_monkey_general_open_corpus.jsonl'\n",
    "\n",
    "with open('seq_monkey_datawhale.jsonl', 'a', encoding='utf-8') as pretrain:\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        data = f.readlines()\n",
    "        for line in tqdm(data, desc=f\"Processing lines in {input_file}\", leave=False):  # 添加行级别的进度条\n",
    "            line = json.loads(line)\n",
    "            text = line['text']\n",
    "            chunks = split_text(text)\n",
    "            for chunk in chunks:\n",
    "                pretrain.write(json.dumps({'text': chunk}, ensure_ascii=False) + '\\n')"
   ],
   "id": "d61ee0c92e268a21",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T07:26:51.761669Z",
     "start_time": "2025-09-15T07:25:28.352097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2 处理SFT数据\n",
    "\n",
    "def convert_message(data):\n",
    "    \"\"\"\n",
    "    将原始数据转换为标准格式\n",
    "    \"\"\"\n",
    "    message = [\n",
    "        {\"role\": \"system\", \"content\": \"你是一个AI助手\"},\n",
    "    ]\n",
    "    for item in data:\n",
    "        if item['from'] == 'human':\n",
    "            message.append({'role': 'user', 'content': item['value']})\n",
    "        elif item['from'] == 'assistant':\n",
    "            message.append({'role': 'assistant', 'content': item['value']})\n",
    "    return message\n",
    "\n",
    "with open('BelleGroup_sft.jsonl', 'a', encoding='utf-8') as sft:\n",
    "    with open('/home/chenyinlin/Data/BelleGroup/train_3.5M_CN.json', 'r', encoding='utf-8') as f:\n",
    "        data = f.readlines()\n",
    "        for item in tqdm(data, desc=\"Processing\", unit=\"lines\"):\n",
    "            item = json.loads(item)\n",
    "            message = convert_message(item['conversations'])\n",
    "            sft.write(json.dumps(message, ensure_ascii=False) + '\\n')"
   ],
   "id": "51a8bcb93fa5fa4d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████████████████████████████████████████████████| 3606402/3606402 [01:04<00:00, 56131.05lines/s]\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-09-15T07:40:06.350670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "import json\n",
    "import os\n",
    "from transformers import AutoTokenizer, PreTrainedTokenizerFast\n",
    "from tokenizers import (\n",
    "    decoders,\n",
    "    models,\n",
    "    pre_tokenizers,\n",
    "    trainers,\n",
    "    Tokenizer,\n",
    ")\n",
    "from tokenizers.normalizers import NFKC\n",
    "from typing import Generator\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "def read_texts_from_jsonl(file_path: str) -> Generator[str, None, None]:\n",
    "    \"\"\"读取JSONL文件并安全提取文本数据\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line_num, line in enumerate(f, 1):\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                if 'text' not in data:\n",
    "                    raise KeyError(f\"Missing 'text' field in line {line_num}\")\n",
    "                yield data['text']\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error decoding JSON in line {line_num}\")\n",
    "                continue\n",
    "            except KeyError as e:\n",
    "                print(e)\n",
    "                continue\n",
    "\n",
    "def create_tokenizer_config(save_dir: str) -> None:\n",
    "    \"\"\"创建完整的tokenizer配置文件\"\"\"\n",
    "    config = {\n",
    "        \"add_bos_token\": False,\n",
    "        \"add_eos_token\": False,\n",
    "        \"add_prefix_space\": True,\n",
    "        \"bos_token\": \"<|im_start|>\",\n",
    "        \"eos_token\": \"<|im_end|>\",\n",
    "        \"pad_token\": \"<|im_end|>\",\n",
    "        \"unk_token\": \"<unk>\",\n",
    "        \"model_max_length\": 1000000000000000019884624838656,\n",
    "        \"clean_up_tokenization_spaces\": False,\n",
    "        \"tokenizer_class\": \"PreTrainedTokenizerFast\",\n",
    "        \"chat_template\": (\n",
    "            \"{% for message in messages %}\"\n",
    "            \"{% if message['role'] == 'system' %}\"\n",
    "            \"<|im_start|>system\\n{{ message['content'] }}<|im_end|>\\n\"\n",
    "            \"{% elif message['role'] == 'user' %}\"\n",
    "            \"<|im_start|>user\\n{{ message['content'] }}<|im_end|>\\n\"\n",
    "            \"{% elif message['role'] == 'assistant' %}\"\n",
    "            \"<|im_start|>assistant\\n{{ message['content'] }}<|im_end|>\\n\"\n",
    "            \"{% endif %}\"\n",
    "            \"{% endfor %}\"\n",
    "            \"{% if add_generation_prompt %}\"\n",
    "            \"{{ '<|im_start|>assistant\\n' }}\"\n",
    "            \"{% endif %}\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # 保存主配置文件\n",
    "    with open(os.path.join(save_dir, \"/home/chenyinlin/Data/tokenizer_config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(config, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    # 创建special_tokens_map.json\n",
    "    special_tokens_map = {\n",
    "        \"bos_token\": \"<|im_start|>\",\n",
    "        \"eos_token\": \"<|im_end|>\",\n",
    "        \"unk_token\": \"<unk>\",\n",
    "        \"pad_token\": \"<|im_end|>\",\n",
    "        \"additional_special_tokens\": [\"<s>\", \"</s>\"]\n",
    "    }\n",
    "    with open(os.path.join(save_dir, \"/home/chenyinlin/Data/special_tokens_map.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(special_tokens_map, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "def train_tokenizer(data_path: str, save_dir: str, vocab_size: int = 8192) -> None:\n",
    "    \"\"\"训练并保存自定义tokenizer\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # 初始化tokenizer\n",
    "    tokenizer = Tokenizer(models.BPE(unk_token=\"<unk>\"))\n",
    "    tokenizer.normalizer = NFKC()  # 添加文本规范化\n",
    "    tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False)\n",
    "    tokenizer.decoder = decoders.ByteLevel()\n",
    "\n",
    "    # 配置特殊token\n",
    "    special_tokens = [\n",
    "        \"<unk>\",\n",
    "        \"<s>\",\n",
    "        \"</s>\",\n",
    "        \"<|im_start|>\",\n",
    "        \"<|im_end|>\"\n",
    "    ]\n",
    "\n",
    "    # 配置训练器\n",
    "    trainer = trainers.BpeTrainer(\n",
    "        vocab_size=vocab_size,\n",
    "        special_tokens=special_tokens,\n",
    "        min_frequency=2,  # 提高低频词过滤\n",
    "        show_progress=True,\n",
    "        initial_alphabet=pre_tokenizers.ByteLevel.alphabet()\n",
    "    )\n",
    "\n",
    "    # 训练tokenizer\n",
    "    print(f\"Training tokenizer with data from {data_path}\")\n",
    "    texts = read_texts_from_jsonl(data_path)\n",
    "    tokenizer.train_from_iterator(texts, trainer=trainer, length=os.path.getsize(data_path))\n",
    "\n",
    "    # 验证特殊token映射\n",
    "    try:\n",
    "        assert tokenizer.token_to_id(\"<unk>\") == 0\n",
    "        assert tokenizer.token_to_id(\"<s>\") == 1\n",
    "        assert tokenizer.token_to_id(\"</s>\") == 2\n",
    "        assert tokenizer.token_to_id(\"<|im_start|>\") == 3\n",
    "        assert tokenizer.token_to_id(\"<|im_end|>\") == 4\n",
    "    except AssertionError as e:\n",
    "        print(\"Special tokens mapping error:\", e)\n",
    "        raise\n",
    "\n",
    "    # 保存tokenizer文件\n",
    "    tokenizer.save(os.path.join(save_dir, \"tokenizer.json\"))\n",
    "\n",
    "    # 创建配置文件\n",
    "    create_tokenizer_config(save_dir)\n",
    "    print(f\"Tokenizer saved to {save_dir}\")\n",
    "\n",
    "def eval_tokenizer(tokenizer_path: str) -> None:\n",
    "    \"\"\"评估tokenizer功能\"\"\"\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading tokenizer: {e}\")\n",
    "        return\n",
    "\n",
    "    # 测试基本属性\n",
    "    print(\"\\n=== Tokenizer基本信息 ===\")\n",
    "    print(f\"Vocab size: {len(tokenizer)}\")\n",
    "    print(f\"Special tokens: {tokenizer.all_special_tokens}\")\n",
    "    print(f\"Special token IDs: {tokenizer.all_special_ids}\")\n",
    "\n",
    "    # 测试聊天模板\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"你是一个AI助手。\"},\n",
    "        {\"role\": \"user\", \"content\": \"How are you?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"I'm fine, thank you. and you?\"},\n",
    "        {\"role\": \"user\", \"content\": \"I'm good too.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"That's great to hear!\"},\n",
    "    ]\n",
    "\n",
    "    print(\"\\n=== 聊天模板测试 ===\")\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        # add_generation_prompt=True\n",
    "    )\n",
    "    print(\"Generated prompt:\\n\", prompt, sep=\"\")\n",
    "\n",
    "    # 测试编码解码\n",
    "    print(\"\\n=== 编码解码测试 ===\")\n",
    "    encoded = tokenizer(prompt, truncation=True, max_length=256)\n",
    "    decoded = tokenizer.decode(encoded[\"input_ids\"], skip_special_tokens=False)\n",
    "    print(\"Decoded text matches original:\", decoded == prompt)\n",
    "\n",
    "    # 测试特殊token处理\n",
    "    print(\"\\n=== 特殊token处理 ===\")\n",
    "    test_text = \"<|im_start|>user\\nHello<|im_end|>\"\n",
    "    encoded = tokenizer(test_text).input_ids\n",
    "    decoded = tokenizer.decode(encoded)\n",
    "    print(f\"Original: {test_text}\")\n",
    "    print(f\"Decoded:  {decoded}\")\n",
    "    print(\"Special tokens preserved:\", decoded == test_text)\n",
    "\n",
    "def main():\n",
    "    # 配置路径\n",
    "    data_path = \"/home/chenyinlin/Data/seq_monkey_datawhale.jsonl\"\n",
    "    save_dir = \"/home/chenyinlin/Data/tokenizer_k\"\n",
    "\n",
    "    # 训练tokenizer\n",
    "    train_tokenizer(\n",
    "        data_path=data_path,\n",
    "        save_dir=save_dir,\n",
    "        vocab_size=6144\n",
    "    )\n",
    "\n",
    "    # 评估tokenizer\n",
    "    eval_tokenizer(save_dir)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ],
   "id": "9efd556a637538aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokenizer with data from /home/chenyinlin/Data/seq_monkey_datawhale.jsonl\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "import numpy as np",
   "id": "3fb741aba7294e0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class PretrainDataset(Dataset):\n",
    "    def __init__(self, data_path, tokenizer, max_length=512):\n",
    "        super().__init__()\n",
    "        self.data_path = data_path\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.padding = 0\n",
    "        with open(data_path, 'r', encoding='utf-8') as f:\n",
    "            self.data = f.readlines()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        sample = json.loads(self.data[index])\n",
    "        text = f\"{self.tokenizer.bos_token}{sample['text']}\"\n",
    "        input_id = self.tokenizer(text).data['input_ids'][:self.max_length]\n",
    "        text_len = len(input_id)\n",
    "        # 没满最大长度的剩余部分\n",
    "        padding_len = self.max_length - text_len\n",
    "        input_id = input_id + [self.padding] * padding_len\n",
    "        # 0表示不计算损失\n",
    "        loss_mask = [1] * text_len + [0] * padding_len\n",
    "\n",
    "        input_id = np.array(input_id)\n",
    "        X = np.array(input_id[:-1]).astype(np.int64)\n",
    "        Y = np.array(input_id[1:]).astype(np.int64)\n",
    "        loss_mask = np.array(loss_mask[1:]).astype(np.int64)\n",
    "        return torch.from_numpy(X), torch.from_numpy(Y), torch.from_numpy(loss_mask)\n"
   ],
   "id": "a9466c05e64d9d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class SFTDataset(Dataset):\n",
    "    def __init__(self, data_path, tokenizer, max_length=512):\n",
    "        super().__init__()\n",
    "        self.data_path = data_path\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.padding = 0\n",
    "        with open(data_path, 'r', encoding='utf-8') as f:\n",
    "            self.data = f.readlines()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def generate_loss_mask(self, input_ids):\n",
    "        # 生成 loss mask, 0 表示不计算损失, 1 表示计算损失\n",
    "        mask = [0] * len(input_ids)\n",
    "        a_sequence = [3, 1074, 537, 500, 203]  # <|im_start|>assistant\\n\n",
    "        a_length = len(a_sequence)\n",
    "        n = len(input_ids)\n",
    "        i = 0\n",
    "\n",
    "        while i <= n - a_length:\n",
    "            # 检查当前位置是否匹配目标子序列\n",
    "            match = True\n",
    "            for k in range(a_length):\n",
    "                if input_ids[i + k] != a_sequence[k]:\n",
    "                    match = False\n",
    "                    break\n",
    "            if match:\n",
    "                # 从子序列结束的位置开始查找第一个4, 4 为 <|im_end|> EOS id\n",
    "                j = None\n",
    "                for idx in range(i + a_length, n):\n",
    "                    if input_ids[idx] == 4:\n",
    "                        j = idx\n",
    "                        break\n",
    "                if j is not None:\n",
    "                    start = i + a_length\n",
    "                    end = j  # 结束位置设为j（包含4）\n",
    "                    # 标记区间为1（包括start到end）\n",
    "                    if start <= end:\n",
    "                        for pos in range(start, end + 1):\n",
    "                            if pos < len(mask):\n",
    "                                mask[pos] = 1\n",
    "                # 跳过当前子序列，避免重叠匹配\n",
    "                i += a_length\n",
    "            else:\n",
    "                i += 1\n",
    "        return mask\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        sample = json.loads(self.data[index])\n",
    "        text = self.tokenizer.apply_chat_template(sample, tokenize=False, add_generation_prompt=False)\n",
    "        input_id = self.tokenizer(text).data['input_ids'][:self.max_length]\n",
    "        text_len = len(input_id)\n",
    "        # 没满最大长度的剩余部分\n",
    "        padding_len = self.max_length - text_len\n",
    "        input_id = input_id + [self.padding] * padding_len\n",
    "        # 0表示不计算损失\n",
    "        loss_mask = self.generate_loss_mask(input_id)\n",
    "\n",
    "        input_id = np.array(input_id)\n",
    "        X = np.array(input_id[:-1]).astype(np.int64)\n",
    "        Y = np.array(input_id[1:]).astype(np.int64)\n",
    "        loss_mask = np.array(loss_mask[1:]).astype(np.int64)\n",
    "        return torch.from_numpy(X), torch.from_numpy(Y), torch.from_numpy(loss_mask)\n"
   ],
   "id": "eddc8d2d4248c497"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "@torch.inference_mode()\n",
    "    def generate(self, idx, stop_id=None, max_new_tokens=256, temperature=1.0, top_k=None):\n",
    "        \"\"\"\n",
    "        给定输入序列 idx（形状为 (bz,seq_len) 的长整型张量），通过多次生成新 token 来完成序列。\n",
    "        在 model.eval() 模式下运行。效率较低的采样版本，没有使用键k/v cache。\n",
    "        \"\"\"\n",
    "        index = idx.shape[1]\n",
    "        for _ in range(max_new_tokens):\n",
    "            # 如果序列上下文过长，截断它到最大长度\n",
    "            idx_cond = idx if idx.size(1) <= self.args.max_seq_len else idx[:, -self.args.max_seq_len:]\n",
    "\n",
    "            # 前向传播获取序列中最后一个位置的 logits\n",
    "            logits = self(idx_cond).logits\n",
    "            logits = logits[:, -1, :] # 只保留最后一个时间步的输出\n",
    "\n",
    "            if temperature == 0.0:\n",
    "                # 选择最有可能的索引\n",
    "                _, idx_next = torch.topk(logits, k=1, dim=-1)\n",
    "            else:\n",
    "                # 缩放 logits 并应用 softmax\n",
    "                logits = logits / temperature\n",
    "                if top_k is not None:\n",
    "                    v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                    logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "                probs = F.softmax(logits, dim=-1)\n",
    "                idx_next = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "\n",
    "            if idx_next == stop_id:\n",
    "                break\n",
    "\n",
    "            # 将采样的索引添加到序列中并继续\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "        return idx[:, index:] # 只返回生成的token\n"
   ],
   "id": "9b95802c63969e24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_lr(it, all):\n",
    "    \"\"\"\n",
    "    计算当前迭代的学习率，使用余弦退火调度策略\n",
    "\n",
    "    学习率调度策略：\n",
    "    1. Warmup阶段：学习率从0线性增长到目标学习率\n",
    "    2. 余弦退火阶段：学习率按余弦函数衰减到最小学习率\n",
    "    3. 超出训练步数后：保持最小学习率\n",
    "\n",
    "    Args:\n",
    "        it (int): 当前迭代步数\n",
    "        all (int): 总迭代步数\n",
    "\n",
    "    Returns:\n",
    "        float: 当前步数对应的学习率\n",
    "    \"\"\"\n",
    "    warmup_iters = args.warmup_iters  # 预热迭代次数\n",
    "    lr_decay_iters = all  # 学习率衰减的总迭代次数\n",
    "    min_lr = args.learning_rate / 10  # 最小学习率，为初始学习率的1/10\n",
    "\n",
    "    # Warmup阶段：线性增长\n",
    "    if it < warmup_iters:\n",
    "        return args.learning_rate * it / warmup_iters\n",
    "\n",
    "    # 超出训练步数：保持最小学习率\n",
    "    if it > lr_decay_iters:\n",
    "        return min_lr\n",
    "\n",
    "    # 余弦退火阶段\n",
    "    decay_ratio = (it - warmup_iters) / (lr_decay_iters - warmup_iters)\n",
    "    assert 0 <= decay_ratio <= 1\n",
    "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio))  # 余弦系数\n",
    "    return min_lr + coeff * (args.learning_rate - min_lr)\n",
    "\n",
    "def train_epoch(epoch):\n",
    "    \"\"\"\n",
    "    训练一个epoch的函数\n",
    "\n",
    "    实现了完整的训练循环，包括：\n",
    "    1. 数据加载和设备转移\n",
    "    2. 动态学习率调整\n",
    "    3. 前向传播和损失计算\n",
    "    4. 梯度累积和反向传播\n",
    "    5. 梯度裁剪和优化器更新\n",
    "    6. 日志记录和模型保存\n",
    "\n",
    "    Args:\n",
    "        epoch (int): 当前epoch编号\n",
    "    \"\"\"\n",
    "    start_time = time.time()  # 记录开始时间\n",
    "\n",
    "    # 遍历数据加载器中的每个batch\n",
    "    for step, (X, Y, loss_mask) in enumerate(train_loader):\n",
    "        # 将数据转移到指定设备（GPU/CPU）\n",
    "        X = X.to(args.device)  # 输入序列\n",
    "        Y = Y.to(args.device)  # 目标序列\n",
    "        loss_mask = loss_mask.to(args.device)  # 损失掩码，用于忽略padding token\n",
    "\n",
    "        # 计算当前步骤的学习率\n",
    "        lr = get_lr(epoch * iter_per_epoch + step, args.epochs * iter_per_epoch)\n",
    "        # 更新优化器中所有参数组的学习率\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "        # 使用混合精度训练上下文\n",
    "        with ctx:\n",
    "            # 前向传播\n",
    "            out = model(X, Y)\n",
    "            # 计算损失并除以累积步数（用于梯度累积）\n",
    "            loss = out.last_loss / args.accumulation_steps\n",
    "            # 将loss_mask展平为一维\n",
    "            loss_mask = loss_mask.view(-1)\n",
    "            # 应用掩码计算有效损失（忽略padding位置）\n",
    "            loss = torch.sum(loss * loss_mask) / loss_mask.sum()\n",
    "\n",
    "        # 使用scaler进行混合精度的反向传播\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # 每accumulation_steps步执行一次优化器更新\n",
    "        if (step + 1) % args.accumulation_steps == 0:\n",
    "            # 取消梯度缩放，准备梯度裁剪\n",
    "            scaler.unscale_(optimizer)\n",
    "            # 梯度裁剪，防止梯度爆炸\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip)\n",
    "\n",
    "            # 执行优化器步骤\n",
    "            scaler.step(optimizer)\n",
    "            # 更新scaler的缩放因子\n",
    "            scaler.update()\n",
    "\n",
    "            # 清零梯度，set_to_none=True可以节省内存\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # 每log_interval步记录一次日志\n",
    "        if step % args.log_interval == 0:\n",
    "            spend_time = time.time() - start_time\n",
    "            # 打印训练进度信息\n",
    "            Logger(\n",
    "                'Epoch:[{}/{}]({}/{}) loss:{:.3f} lr:{:.7f} epoch_Time:{}min;'.format(\n",
    "                    epoch + 1,\n",
    "                    args.epochs,\n",
    "                    step,\n",
    "                    iter_per_epoch,\n",
    "                    loss.item() * args.accumulation_steps,  # 恢复真实的loss值\n",
    "                    optimizer.param_groups[-1]['lr'],\n",
    "                    spend_time / (step + 1) * iter_per_epoch // 60 - spend_time // 60))\n",
    "\n",
    "            # 如果启用SwanLab，记录训练指标\n",
    "            if args.use_swanlab:\n",
    "                swanlab.log({\n",
    "                    \"loss\": loss.item() * args.accumulation_steps,\n",
    "                    \"lr\": optimizer.param_groups[-1]['lr']\n",
    "                })\n",
    "\n",
    "        # 每save_interval步保存一次模型\n",
    "        if (step + 1) % args.save_interval == 0:\n",
    "            model.eval()  # 切换到评估模式\n",
    "            # 构建检查点文件名\n",
    "            ckp = f'{args.save_dir}/pretrain_{lm_config.dim}_{lm_config.n_layers}_{lm_config.vocab_size}.pth'\n",
    "\n",
    "            # 处理多卡保存：如果是DataParallel模型，需要访问.module属性\n",
    "            state_dict = model.module.state_dict() if isinstance(model, torch.nn.DataParallel) else model.state_dict()\n",
    "            torch.save(state_dict, ckp)\n",
    "            model.train()  # 切换回训练模式\n",
    "\n",
    "        # 每20000步保存一个带步数标记的检查点\n",
    "        if (step + 1) % 20000 == 0:\n",
    "            model.eval()\n",
    "            # 构建带步数的检查点文件名\n",
    "            ckp = f'{args.save_dir}/pretrain_{lm_config.dim}_{lm_config.n_layers}_{lm_config.vocab_size}_step{step+1}.pth'\n",
    "\n",
    "            # 保存模型状态字典\n",
    "            state_dict = model.module.state_dict() if isinstance(model, torch.nn.DataParallel) else model.state_dict()\n",
    "            torch.save(state_dict, ckp)\n",
    "            model.train()\n",
    "\n",
    "\n",
    "def init_model():\n",
    "    \"\"\"\n",
    "    初始化模型和分词器\n",
    "\n",
    "    功能包括：\n",
    "    1. 加载预训练的分词器\n",
    "    2. 创建Transformer模型\n",
    "    3. 设置多GPU并行训练（如果可用）\n",
    "    4. 将模型移动到指定设备\n",
    "    5. 统计并打印模型参数量\n",
    "\n",
    "    Returns:\n",
    "        tuple: (model, tokenizer) 初始化后的模型和分词器\n",
    "    \"\"\"\n",
    "    def count_parameters(model):\n",
    "        \"\"\"\n",
    "        统计模型中可训练参数的数量\n",
    "\n",
    "        Args:\n",
    "            model: PyTorch模型\n",
    "\n",
    "        Returns:\n",
    "            int: 可训练参数总数\n",
    "        \"\"\"\n",
    "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    # 从本地路径加载预训练的分词器\n",
    "    tokenizer = AutoTokenizer.from_pretrained('./tokenizer_k/')\n",
    "\n",
    "    # 根据配置创建Transformer模型\n",
    "    model = Transformer(lm_config)\n",
    "\n",
    "    # 多卡初始化：检查可用GPU数量并设置DataParallel\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    if num_gpus > 1:\n",
    "        Logger(f\"Using {num_gpus} GPUs with DataParallel!\")\n",
    "        # 使用DataParallel包装模型以支持多GPU训练\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # 将模型移动到指定设备（GPU或CPU）\n",
    "    model = model.to(args.device)\n",
    "\n",
    "    # 计算并打印模型参数量（以百万为单位）\n",
    "    Logger(f'LLM总参数量：{count_parameters(model) / 1e6:.3f} 百万')\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ==================== 命令行参数解析 ====================\n",
    "    parser = argparse.ArgumentParser(description=\"Tiny-LLM Pretraining\")\n",
    "\n",
    "    # 基础训练参数\n",
    "    parser.add_argument(\"--out_dir\", type=str, default=\"base_model_215M\", help=\"模型输出目录\")\n",
    "    parser.add_argument(\"--epochs\", type=int, default=1, help=\"训练轮数\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=64, help=\"批次大小\")\n",
    "    parser.add_argument(\"--learning_rate\", type=float, default=2e-4, help=\"学习率\")\n",
    "    parser.add_argument(\"--device\", type=str, default=\"cuda:0\" if torch.cuda.is_available() else \"cpu\", help=\"训练设备\")\n",
    "    parser.add_argument(\"--dtype\", type=str, default=\"bfloat16\", help=\"数据类型\")\n",
    "\n",
    "    # 实验跟踪和数据加载参数\n",
    "    parser.add_argument(\"--use_swanlab\", action=\"store_true\", help=\"是否使用SwanLab进行实验跟踪\")\n",
    "    parser.add_argument(\"--num_workers\", type=int, default=8, help=\"数据加载的工作进程数\")\n",
    "    parser.add_argument(\"--data_path\", type=str, default=\"./seq_monkey_datawhale.jsonl\", help=\"训练数据路径\")\n",
    "\n",
    "    # 训练优化参数\n",
    "    parser.add_argument(\"--accumulation_steps\", type=int, default=8, help=\"梯度累积步数\")\n",
    "    parser.add_argument(\"--grad_clip\", type=float, default=1.0, help=\"梯度裁剪阈值\")\n",
    "    parser.add_argument(\"--warmup_iters\", type=int, default=0, help=\"学习率预热迭代次数\")\n",
    "\n",
    "    # 日志和保存参数\n",
    "    parser.add_argument(\"--log_interval\", type=int, default=100, help=\"日志记录间隔\")\n",
    "    parser.add_argument(\"--save_interval\", type=int, default=1000, help=\"模型保存间隔\")\n",
    "\n",
    "    # 多GPU训练参数\n",
    "    parser.add_argument(\"--gpus\", type=str, default='0,1,2,3,4,5,6,7', help=\"使用的GPU ID，用逗号分隔 (例如: '0,1,2')\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # ==================== GPU环境设置 ====================\n",
    "    # 设置可见的GPU设备\n",
    "    if args.gpus is not None:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpus\n",
    "        # 自动设置主设备为第一个可用GPU\n",
    "        if torch.cuda.is_available():\n",
    "            args.device = \"cuda:0\"\n",
    "        else:\n",
    "            args.device = \"cpu\"\n",
    "\n",
    "    # ==================== 实验跟踪初始化 ====================\n",
    "    if args.use_swanlab:\n",
    "        # 注意：使用前需要先登录 swanlab.login(api_key='your key')\n",
    "        run = swanlab.init(\n",
    "            project=\"Happy-LLM\",  # 项目名称\n",
    "            experiment_name=\"Pretrain-215M\",  # 实验名称\n",
    "            config=args,  # 保存所有超参数\n",
    "        )\n",
    "\n",
    "    # ==================== 模型配置 ====================\n",
    "    # 定义语言模型的配置参数\n",
    "    lm_config = ModelConfig(\n",
    "        dim=1024,      # 模型维度\n",
    "        n_layers=18,   # Transformer层数\n",
    "    )\n",
    "\n",
    "    # ==================== 训练环境设置 ====================\n",
    "    max_seq_len = lm_config.max_seq_len  # 最大序列长度\n",
    "    args.save_dir = os.path.join(args.out_dir)  # 模型保存目录\n",
    "\n",
    "    # 创建必要的目录\n",
    "    os.makedirs(args.out_dir, exist_ok=True)\n",
    "\n",
    "    # 设置随机种子以确保结果可复现\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    # 确定设备类型（用于选择合适的上下文管理器）\n",
    "    device_type = \"cuda\" if \"cuda\" in args.device else \"cpu\"\n",
    "\n",
    "    # 设置混合精度训练的上下文管理器\n",
    "    # CPU训练时使用nullcontext，GPU训练时使用autocast\n",
    "    ctx = nullcontext() if device_type == \"cpu\" else torch.cuda.amp.autocast()\n",
    "\n",
    "    # ==================== 模型和数据初始化 ====================\n",
    "    # 初始化模型和分词器\n",
    "    model, tokenizer = init_model()\n",
    "\n",
    "    # 创建训练数据集\n",
    "    train_ds = PretrainDataset(args.data_path, tokenizer, max_length=max_seq_len)\n",
    "\n",
    "    # 创建数据加载器\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=args.batch_size,  # 批次大小\n",
    "        pin_memory=True,             # 将数据加载到固定内存中，加速GPU传输\n",
    "        drop_last=False,             # 不丢弃最后一个不完整的批次\n",
    "        shuffle=True,                # 随机打乱数据\n",
    "        num_workers=args.num_workers # 数据加载的并行工作进程数\n",
    "    )\n",
    "\n",
    "    # ==================== 优化器和训练组件初始化 ====================\n",
    "    # 初始化混合精度训练的梯度缩放器\n",
    "    # 只有在使用float16或bfloat16时才启用\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=(args.dtype in ['float16', 'bfloat16']))\n",
    "\n",
    "    # 初始化Adam优化器\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "\n",
    "    # ==================== 开始训练 ====================\n",
    "    # 计算每个epoch的迭代次数\n",
    "    iter_per_epoch = len(train_loader)\n",
    "\n",
    "    # 开始训练循环\n",
    "    for epoch in range(args.epochs):\n",
    "        train_epoch(epoch)\n"
   ],
   "id": "462289cfb4533701"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

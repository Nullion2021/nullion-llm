# Nullion LLM

ä¸€ä¸ªä»é›¶å¼€å§‹å­¦ä¹ å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œå¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆLLM-Vï¼‰å®ç°çš„é¡¹ç›®ã€‚æœ¬é¡¹ç›®å‚è€ƒäº† [MiniMind](https://github.com/jingyaogong/minimind/tree/master) é¡¹ç›®ï¼Œæ—¨åœ¨æ·±å…¥ç†è§£å’Œå®è·µå¤§æ¨¡å‹çš„å„ä¸ªæ ¸å¿ƒç»„ä»¶ã€‚

## ğŸ¯ é¡¹ç›®ç›®æ ‡

- æ·±å…¥å­¦ä¹ å¤§è¯­è¨€æ¨¡å‹çš„æ¶æ„å’Œå®ç°åŸç†
- æŒæ¡Transformerã€æ³¨æ„åŠ›æœºåˆ¶ã€ä½ç½®ç¼–ç ç­‰æ ¸å¿ƒæŠ€æœ¯
- ä¸ºåç»­å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆLLM-Vï¼‰çš„å­¦ä¹ æ‰“ä¸‹åŸºç¡€
- ä»é›¶å¼€å§‹æ„å»ºå®Œæ•´çš„å¤§æ¨¡å‹ç³»ç»Ÿ

## ğŸ“ é¡¹ç›®ç»“æ„

```
nullion-llm/
â”œâ”€â”€ model/                   # æ¨¡å‹å®ç°ç›®å½•
â”‚   â”œâ”€â”€ __init__.py         # æ¨¡å—åˆå§‹åŒ–
â”‚   â”œâ”€â”€ nullion.py          # ä¸»è¦æ¨¡å‹å®ç°
â”‚   â”œâ”€â”€ model_nullion.py    # å‚è€ƒæ¨¡å‹å®ç°
â”‚   â”œâ”€â”€ tokenizer.json       # åˆ†è¯å™¨è¯æ±‡è¡¨
â”‚   â””â”€â”€ tokenizer_config.json # åˆ†è¯å™¨é…ç½®
â”œâ”€â”€ Data/                    # æ•°æ®å¤„ç†ç›®å½•
â”‚   â”œâ”€â”€ lm_dataset.py       # æ•°æ®é›†ç±»å®ç°
â”‚   â””â”€â”€ *.jsonl             # è®­ç»ƒæ•°æ®æ–‡ä»¶
â”œâ”€â”€ test/                    # æµ‹è¯•æ–‡ä»¶ç›®å½•
â”‚   â”œâ”€â”€ modeltest.py        # æ¨¡å‹æµ‹è¯•æ–‡ä»¶
â”‚   â””â”€â”€ datasettest.py      # æ•°æ®é›†æµ‹è¯•æ–‡ä»¶
â”œâ”€â”€ scripts/                 # è®­ç»ƒè„šæœ¬ç›®å½•
â”‚   â””â”€â”€ train_pretrain.py   # é¢„è®­ç»ƒè„šæœ¬
â””â”€â”€ README.md               # é¡¹ç›®è¯´æ˜æ–‡æ¡£
```

## ğŸš€ æ ¸å¿ƒåŠŸèƒ½

### æ¨¡å‹æ¶æ„ç‰¹æ€§

- **Transformeræ¶æ„**: å®Œæ•´å®ç°äº†æ ‡å‡†çš„Transformeræ¶æ„
- **æ³¨æ„åŠ›æœºåˆ¶**: å¤šå¤´æ³¨æ„åŠ›ï¼ˆMulti-Head Attentionï¼‰
- **ä½ç½®ç¼–ç **: RoPEï¼ˆRotary Position Embeddingï¼‰æ—‹è½¬ä½ç½®ç¼–ç 
- **å½’ä¸€åŒ–**: RMSNormå½’ä¸€åŒ–å±‚
- **æ¿€æ´»å‡½æ•°**: SwiGLUæ¿€æ´»å‡½æ•°
- **æƒé‡å…±äº«**: è¯åµŒå…¥ä¸è¾“å‡ºå±‚æƒé‡ç»‘å®š

### é…ç½®ç³»ç»Ÿ

- **NullionConfig**: å®Œæ•´çš„æ¨¡å‹é…ç½®ç±»ï¼Œæ”¯æŒï¼š
  - æ¨¡å‹ç»´åº¦é…ç½®ï¼ˆhidden_size, intermediate_sizeï¼‰
  - æ³¨æ„åŠ›å¤´é…ç½®ï¼ˆnum_attention_headsï¼‰
  - ä½ç½®ç¼–ç é…ç½®ï¼ˆrope_theta, max_position_embeddingsï¼‰
  - å½’ä¸€åŒ–å’ŒDropouté…ç½®

### æ ¸å¿ƒç»„ä»¶

1. **NullionConfig**: æ¨¡å‹é…ç½®ç®¡ç†
2. **RMSNorm**: å‡æ–¹æ ¹å½’ä¸€åŒ–å±‚
3. **Attention**: å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶å®ç°
4. **FeedForward**: SwiGLUå‰é¦ˆç½‘ç»œ
5. **ModelBlock**: Transformerå—å®ç°
6. **NullionModel**: æ¨¡å‹ä¸»ä½“æ¶æ„
7. **NullionForCausalLM**: å› æœè¯­è¨€å»ºæ¨¡å°è£…

## ğŸ› ï¸ æŠ€æœ¯æ ˆ

- **æ¡†æ¶**: PyTorch
- **ç”Ÿæ€**: Transformers
- **ä¸»è¦åº“**: torch, transformers, numpy
- **ç‰¹æ€§**: FlashAttentionæ”¯æŒã€RoPEå®ç°

## ğŸ“‹ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

```bash
Python >= 3.8
PyTorch >= 1.12.0
transformers >= 4.20.0
```

### è¿è¡Œæµ‹è¯•

```bash
# è¿è¡Œæ¨¡å‹æµ‹è¯•
python test/modeltest.py

# æµ‹è¯•æ³¨æ„åŠ›æœºåˆ¶
python test/modeltest.py
```

### åŸºæœ¬ä½¿ç”¨

```python
from model.nullion import NullionConfig, NullionForCausalLM

# åˆ›å»ºæ¨¡å‹é…ç½®
config = NullionConfig(
    hidden_size=512,
    num_attention_heads=8,
    num_hidden_layers=8,
    vocab_size=6400
)

# åˆå§‹åŒ–æ¨¡å‹
model = NullionForCausalLM(config)

# å‰å‘ä¼ æ’­
input_ids = torch.randint(0, config.vocab_size, (1, 10))
output = model(input_ids)
```

## ğŸ”§ æ¨¡å‹é…ç½®

### åŸºç¡€é…ç½®
```python
config = NullionConfig(
    hidden_size=512,              # éšè—å±‚ç»´åº¦
    num_attention_heads=8,       # æ³¨æ„åŠ›å¤´æ•°
    num_hidden_layers=8,          # éšè—å±‚æ•°
    vocab_size=6400,              # è¯æ±‡è¡¨å¤§å°
    max_position_embeddings=32768,  # æœ€å¤§åºåˆ—é•¿åº¦
    rope_theta=1000000.0,         # RoPEå‚æ•°
    rms_norm_eps=1e-5,           # å½’ä¸€åŒ–epsilon
    dropout=0.1                  # Dropoutæ¦‚ç‡
)
```


## ğŸ“Š æ€§èƒ½ç‰¹æ€§

### æ³¨æ„åŠ›æœºåˆ¶ä¼˜åŒ–
- **FlashAttention**: æ”¯æŒä¼˜åŒ–çš„æ³¨æ„åŠ›è®¡ç®—
- **RoPE**: é«˜æ•ˆçš„æ—‹è½¬ä½ç½®ç¼–ç 

### æ¨¡å‹æ¶æ„ä¼˜åŒ–
- **SwiGLU**: æ›´é«˜æ•ˆçš„å‰é¦ˆç½‘ç»œæ¿€æ´»å‡½æ•°
- **RMSNorm**: æ›´ç¨³å®šçš„å½’ä¸€åŒ–æ–¹æ³•
- **æƒé‡å…±äº«**: å‡å°‘å‚æ•°é‡ï¼Œæå‡è®­ç»ƒç¨³å®šæ€§


## ğŸ§ª æµ‹è¯•è¦†ç›–

é¡¹ç›®åŒ…å«å®Œæ•´çš„æµ‹è¯•å¥—ä»¶ï¼š

- **é…ç½®æµ‹è¯•**: éªŒè¯NullionConfigçš„å„é¡¹å‚æ•°
- **ä½ç½®ç¼–ç æµ‹è¯•**: æµ‹è¯•RoPEé¢„è®¡ç®—å’Œåº”ç”¨
- **æ³¨æ„åŠ›æœºåˆ¶æµ‹è¯•**: éªŒè¯å¤šå¤´æ³¨æ„åŠ›çš„æ­£ç¡®æ€§
- **æ¨¡å‹åˆ›å»ºæµ‹è¯•**: æµ‹è¯•åŸºæœ¬æ¨¡å‹çš„åˆå§‹åŒ–
- **å‰å‘ä¼ æ’­æµ‹è¯•**: éªŒè¯æ¨¡å‹çš„å®Œæ•´æ¨ç†æµç¨‹
- **ç”Ÿæˆæµ‹è¯•**: æµ‹è¯•æ–‡æœ¬ç”ŸæˆåŠŸèƒ½

## ğŸ“š å­¦ä¹ è·¯å¾„

### ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€æ¶æ„
1. ç†è§£TransformeråŸºæœ¬æ¶æ„
2. å®ç°å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶
3. æŒæ¡ä½ç½®ç¼–ç åŸç†

### ç¬¬äºŒé˜¶æ®µï¼šä¼˜åŒ–æŠ€æœ¯
1. å­¦ä¹ RoPEå®ç°
2. æŒæ¡FlashAttention

### ç¬¬ä¸‰é˜¶æ®µï¼šé«˜çº§ç‰¹æ€§
1. å­¦ä¹ æ¨¡å‹å¹¶è¡ŒæŠ€æœ¯
2. æ¢ç´¢å¤šæ¨¡æ€æ‰©å±•

## ğŸ”„ å¼€å‘è®¡åˆ’

- [x] åŸºç¡€Transformeræ¶æ„å®ç°
- [x] RoPEä½ç½®ç¼–ç 
- [x] å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶
- [x] RMSNormå½’ä¸€åŒ–
- [x] SwiGLUæ¿€æ´»å‡½æ•°
- [ ] GQAæ”¯æŒ
- [ ] MoEæ¶æ„å®ç°
- [ ] æ¨¡å‹è®­ç»ƒè„šæœ¬
- [ ] å¤šæ¨¡æ€æ‰©å±•ï¼ˆLLM-Vï¼‰
- [ ] æ¨ç†ä¼˜åŒ–
- [ ] æ¨¡å‹é‡åŒ–
- [ ] åˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒ

## ğŸ“ ä»£ç é£æ ¼

- ä½¿ç”¨ä¸­æ–‡æ³¨é‡Šï¼Œä¾¿äºç†è§£
- éµå¾ªPEP 8ä»£ç è§„èŒƒ
- å®Œæ•´çš„å‡½æ•°å’Œç±»æ–‡æ¡£
- æ¨¡å—åŒ–è®¾è®¡ï¼Œä¾¿äºæ‰©å±•

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤Issueå’ŒPull Requestæ¥æ”¹è¿›é¡¹ç›®ï¼

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®ä»…ä¾›å­¦ä¹ å’Œç ”ç©¶ä½¿ç”¨ã€‚

## ğŸ“– å‚è€ƒèµ„æ–™

- [MiniMindé¡¹ç›®](https://github.com/jingyaogong/minimind/tree/master)
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
- [RoPE: Rotary Position Embedding](https://arxiv.org/abs/2104.09864)

## ğŸ“ å¼€å‘æ—¥å¿—

### 2025å¹´9æœˆ22æ—¥

#### æ•°æ®é›†å¤„ç†æ¨¡å—å®ç° (Data/lm_dataset.py)
å®ç°äº†ä¸‰ä¸ªå®Œæ•´çš„æ•°æ®é›†ç±»ï¼Œæ”¯æŒä¸åŒè®­ç»ƒé˜¶æ®µçš„æ•°æ®å¤„ç†ï¼š

1. **PretrainDataset**: é¢„è®­ç»ƒæ•°æ®é›†
   - æ”¯æŒJSONLæ ¼å¼çš„æ–‡æœ¬æ•°æ®åŠ è½½
   - è‡ªåŠ¨åºåˆ—é•¿åº¦æ§åˆ¶å’Œæˆªæ–­
   - ç”Ÿæˆè‡ªå›å½’è®­ç»ƒçš„è¾“å…¥-ç›®æ ‡å¯¹
   - åˆ›å»ºæŸå¤±æ©ç ï¼Œæ”¯æŒå¡«å……tokençš„å¿½ç•¥

2. **SFTDataset**: ç›‘ç£å¾®è°ƒæ•°æ®é›†
   - å¤„ç†å¯¹è¯æ ¼å¼çš„æ•°æ®
   - ä½¿ç”¨èŠå¤©æ¨¡æ¿æ ¼å¼åŒ–å¯¹è¯
   - æ™ºèƒ½æŸå¤±æ©ç ï¼Œåªå¯¹åŠ©æ‰‹å›å¤è®¡ç®—æŸå¤±
   - æ”¯æŒå¤šè½®å¯¹è¯æ•°æ®å¤„ç†

3. **DPODataset**: ç›´æ¥åå¥½ä¼˜åŒ–æ•°æ®é›†
   - å¤„ç†chosen/rejectedåå¥½å¯¹æ•°æ®
   - ä¸ºchosenå’Œrejectedå›å¤åˆ†åˆ«ç”Ÿæˆè®­ç»ƒæ•°æ®
   - ä¿æŒæ•°æ®ä¸€è‡´æ€§ï¼Œä¾¿äºåå¥½å­¦ä¹ 

#### åˆ†è¯å™¨é…ç½®æ–‡ä»¶
åœ¨model/ç›®å½•ä¸‹æ·»åŠ äº†tokenizerç›¸å…³æ–‡ä»¶ï¼š

- **tokenizer.json**: åˆ†è¯å™¨è¯æ±‡è¡¨å’Œç¼–ç è§„åˆ™
- **tokenizer_config.json**: åˆ†è¯å™¨é…ç½®å‚æ•°å’Œç‰¹æ®Šæ ‡è®°å®šä¹‰
- æ”¯æŒæœ¬åœ°åŠ è½½ï¼Œæ— éœ€ç½‘ç»œä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹

#### æ•°æ®å¤„ç†ç‰¹æ€§
- **æ¨¡å—åŒ–è®¾è®¡**: ä¸‰ä¸ªæ•°æ®é›†ç±»ç»§æ‰¿ç»Ÿä¸€æ¥å£ï¼Œæ˜“äºæ‰©å±•
- **çµæ´»æ€§**: æ”¯æŒä¸åŒçš„tokenizerå’Œåºåˆ—é•¿åº¦é…ç½®
- **æ•ˆç‡ä¼˜åŒ–**: æ‰¹é‡å¤„ç†å’Œå†…å­˜ä¼˜åŒ–
- **å¥å£®æ€§**: å®Œå–„çš„é”™è¯¯å¤„ç†å’Œæ•°æ®éªŒè¯

#### æµ‹è¯•æ¡†æ¶
- **datasettest.py**: å®Œæ•´çš„æ•°æ®é›†æµ‹è¯•å¥—ä»¶
- **simple_test.py**: ç®€åŒ–çš„æµ‹è¯•è„šæœ¬ï¼Œä¾¿äºè°ƒè¯•
- æ”¯æŒæœ¬åœ°tokenizeråŠ è½½ï¼Œé¿å…ç½‘ç»œä¾èµ–

#### é¢„è®­ç»ƒè„šæœ¬ä½¿ç”¨ (trainer/train_pretrain.py)
æ”¯æŒå•GPUå’Œå¤šGPUåˆ†å¸ƒå¼è®­ç»ƒï¼š

**å•GPUè®­ç»ƒ**:
```bash
# åŸºæœ¬è®­ç»ƒ
python trainer/train_pretrain.py \
    --epochs 1 \
    --batch_size 32 \
    --learning_rate 5e-4 \
    --device cuda:0 \
    --max_seq_len 512 \
    --data_path /path/to/pretrain_data.jsonl

# ä½¿ç”¨wandbè®°å½•
python trainer/train_pretrain.py \
    --epochs 2 \
    --batch_size 16 \
    --learning_rate 1e-4 \
    --use_wandb \
    --wandb_project Nullion-Pretrain \
    --save_interval 200 \
    --log_interval 50
```

**å¤šGPUåˆ†å¸ƒå¼è®­ç»ƒ**:
```bash
# ä½¿ç”¨torch runè¿›è¡Œå¤šGPUè®­ç»ƒ
torch run --nproc_per_node=4 trainer/train_pretrain.py \
    --epochs 3 \
    --batch_size 8 \
    --learning_rate 5e-4 \
    --ddp \
    --accumulation_steps 4 \
    --max_seq_len 1024 \
    --hidden_size 768 \
    --num_hidden_layers 12

# 8å¡è®­ç»ƒç¤ºä¾‹
torch run --nproc_per_node=8 trainer/train_pretrain.py \
    --epochs 1 \
    --batch_size 4 \
    --learning_rate 1e-3 \
    --ddp \
    --accumulation_steps 8 \
    --use_wandb \
    --wandb_project Nullion-Large
```

**å…³é”®å‚æ•°è¯´æ˜**:
- `--epochs`: è®­ç»ƒè½®æ•°
- `--batch_size`: æ¯ä¸ªGPUçš„æ‰¹æ¬¡å¤§å°
- `--learning_rate`: å­¦ä¹ ç‡
- `--ddp`: å¯ç”¨åˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œè®­ç»ƒ
- `--accumulation_steps`: æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼Œæ¨¡æ‹Ÿæ›´å¤§batch size
- `--hidden_size`: æ¨¡å‹éšè—å±‚ç»´åº¦
- `--num_hidden_layers`: Transformerå±‚æ•°
- `--max_seq_len`: æœ€å¤§åºåˆ—é•¿åº¦
- `--use_wandb`: å¯ç”¨wandbè®°å½•è®­ç»ƒè¿‡ç¨‹

---

## ğŸ› å¸¸è§é”™è¯¯å’Œè§£å†³æ–¹æ¡ˆ

### CUDAç´¢å¼•è¶Šç•Œé”™è¯¯

**é”™è¯¯ä¿¡æ¯**: `../aten/src/ATen/native/cuda/Indexing.cu:1289: indexSelectLargeIndex: block: [153,0,0], thread: [96,0,0] Assertion 'srcIndex < srcSelectDimSize' failed.`

**é—®é¢˜åŸå› **:
- ä½¿ç”¨äº†é”™è¯¯çš„åˆ†è¯å™¨åŠ è½½å‡½æ•°`PreTrainedTokenizerFast`ï¼Œåº”è¯¥ä½¿ç”¨`AutoTokenizer`
- `PreTrainedTokenizerFast`å¯èƒ½äº§ç”Ÿè¶…å‡ºæ¨¡å‹`vocab_size`èŒƒå›´çš„token ID
- ä¾‹å¦‚ï¼šæ¨¡å‹`vocab_size=6400`ï¼Œä½†è¾“å…¥åŒ…å«äº†token ID 6401

**è§£å†³æ–¹æ¡ˆ**:
1. åœ¨æ¨¡å‹å‰å‘ä¼ æ’­ä¸­æ·»åŠ è¾“å…¥éªŒè¯
2. ä½¿ç”¨`torch.clamp()`å°†è¶Šç•Œçš„token IDé™åˆ¶åœ¨æœ‰æ•ˆèŒƒå›´å†…
3. æ£€æŸ¥åˆ†è¯å™¨é…ç½®æ˜¯å¦ä¸æ¨¡å‹é…ç½®åŒ¹é…

### MoEç›¸å…³é”™è¯¯

**é”™è¯¯ä¿¡æ¯**: `TypeError: unsupported operand type(s) for +=: 'Tensor' and 'NoneType'`

**é—®é¢˜åŸå› **:
- è®­ç»ƒä»£ç å°è¯•æ·»åŠ `res.aux_loss`ï¼ˆNoneï¼‰åˆ°æŸå¤±å¼ é‡
- ä»£ç ä¸­åŒ…å«äº†æœªä½¿ç”¨çš„MoEï¼ˆMixture of Expertsï¼‰ç›¸å…³é€»è¾‘

**è§£å†³æ–¹æ¡ˆ**:
1. ç§»é™¤è®­ç»ƒè„šæœ¬ä¸­çš„MoEè·¯å¾„é€»è¾‘
2. æ¸…ç†æ¨¡å‹ä»£ç ä¸­çš„MoEç›¸å…³æ³¨é‡Š
3. ç®€åŒ–æ¨¡å‹ä¿å­˜è·¯å¾„ï¼Œä¸å†åŒ…å«MoEç›¸å…³å‚æ•°

### åˆ†è¯å™¨åŠ è½½é—®é¢˜

**é—®é¢˜ç°è±¡**:
- æœ¬åœ°ç¼ºå°‘tokenizeræ–‡ä»¶ä½†è¿è¡Œç¯å¢ƒå­˜åœ¨
- åˆ†è¯å™¨ç”Ÿæˆçš„token IDä¸æ¨¡å‹vocab_sizeä¸åŒ¹é…

**è§£å†³æ–¹æ¡ˆ**:
1. ä½¿ç”¨`AutoTokenizer.from_pretrained()`æ›¿ä»£`PreTrainedTokenizerFast`
2. ç¡®ä¿åˆ†è¯å™¨è¯æ±‡è¡¨å¤§å°ä¸æ¨¡å‹é…ç½®ä¸€è‡´
3. éªŒè¯ç‰¹æ®Štokençš„IDæ˜ å°„æ˜¯å¦æ­£ç¡®

---

**å­¦ä¹ ä»é›¶å¼€å§‹ï¼Œæ·±å…¥ç†è§£å¤§æ¨¡å‹çš„å¥¥ç§˜ï¼** ğŸš€